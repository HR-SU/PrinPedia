# 张哲溢的工作日志

## 第一周

### 7-6

小组讨论、分工。

### 7-7

下载维基百科官方发布的历史数据，用JWPL(Java Wikipedia Library)进行解包，但结果不是很理想。

解出来为txt格式，组织形式非常类似csv，含有大量<ref/>标签，且没有显式的目录结构。

因此转向自己写爬虫，抓取维基百科的数据，组织成更符合数据库、后端要求的数据，以供使用。

### 7-8

用python写了一个简单的抓取网页内容的程序，能初步将指定网页解析成需要的数据形式，保存在txt中。

### 7-9

抓取了10个维基百科页面的数据，作为临时测试数据提交给数据库、后端。

学习pymongo库，直接对数据库进行读写。根据数据库、后端的需要，修改数据格式。

### 7-10

继续修改数据格式。对content(目录)的字符串处理带来了一定的困难。

开始研究和考虑如何自动地不重复地爬取维基百科的词条。

发现抓取的指定网页的超链接(维基百科词条中会有非常多的指向维基百科其他词条的超链接)重复率很高。
